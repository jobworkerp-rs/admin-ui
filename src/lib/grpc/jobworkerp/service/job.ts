// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.8.3
//   protoc               v6.33.1
// source: jobworkerp/service/job.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import { Empty, JobProcessingStatus, Priority, ResultOutputItem } from "../data/common";
import { Job, JobId } from "../data/job";
import { JobResult } from "../data/job_result";
import { WorkerId } from "../data/worker";
import { CountCondition, CountResponse, FindListRequest, SuccessResponse } from "./common";

export const protobufPackage = "jobworkerp.service";

export interface CreateJobResponse {
  /** generated id */
  id:
    | JobId
    | undefined;
  /** direct job result worker only */
  result?: JobResult | undefined;
}

export interface OptionalJobResponse {
  data?: Job | undefined;
}

export interface JobRequest {
  workerId?: WorkerId | undefined;
  workerName?:
    | string
    | undefined;
  /** argument for the job(protobuf serialized) */
  args: Uint8Array;
  /** prevent from registering the same keys job in queue at the same time */
  uniqKey?:
    | string
    | undefined;
  /**
   * time to execute job (epoch milliseconds)(not specify 0 explicitly)
   * job priority(high, medium, low)
   */
  runAfterTime?: string | undefined;
  priority?:
    | Priority
    | undefined;
  /** valid only for run_after or periodic worker jobs */
  timeout?:
    | string
    | undefined;
  /**
   * Runner implementation to use for MCP/Plugin runners
   * - Optional: For normal runners (will be ignored)
   * - Required: For multi-tool MCP runners
   * - Auto-selected: When omitted for single-tool MCP runners
   */
  using?: string | undefined;
}

export interface FindQueueListRequest {
  limit?: number | undefined;
  channel?: string | undefined;
}

export interface FindListWithProcessingStatusRequest {
  status: JobProcessingStatus;
  limit?: number | undefined;
}

export interface JobAndStatus {
  job: Job | undefined;
  status?: JobProcessingStatus | undefined;
}

export interface JobProcessingStatusResponse {
  id: JobId | undefined;
  status: JobProcessingStatus;
}

export interface OptionalJobProcessingStatusResponse {
  status?: JobProcessingStatus | undefined;
}

export interface FindJobProcessingStatusRequest {
  /** Status filter */
  status?:
    | JobProcessingStatus
    | undefined;
  /** Worker ID filter */
  workerId?:
    | string
    | undefined;
  /** Channel filter */
  channel?:
    | string
    | undefined;
  /**
   * Long-running job filter (milliseconds)
   * Example: 600000 (10 minutes) to filter jobs running for more than 10 minutes
   */
  minElapsedTimeMs?:
    | string
    | undefined;
  /** Pagination */
  limit?:
    | number
    | undefined;
  /** Default: 0 */
  offset?:
    | number
    | undefined;
  /** Sort order */
  descending?: boolean | undefined;
}

export interface JobProcessingStatusDetailResponse {
  id: JobId | undefined;
  status: JobProcessingStatus;
  workerId: string;
  channel: string;
  priority: number;
  enqueueTime: string;
  startTime?: string | undefined;
  pendingTime?: string | undefined;
  isStreamable?: boolean | undefined;
  broadcastResults?:
    | boolean
    | undefined;
  /** Last RDB update time (for detecting sync delay) */
  updatedAt: string;
}

/** Cleanup request message */
export interface CleanupRequest {
  /**
   * Optional: Override default retention hours (for testing purposes)
   * If not set, uses JOB_STATUS_RETENTION_HOURS from environment
   */
  retentionHoursOverride?: string | undefined;
}

/** Cleanup response message */
export interface CleanupResponse {
  /** Number of records deleted */
  deletedCount: string;
  /** Cutoff timestamp used for deletion (milliseconds since epoch) */
  cutoffTime: string;
  /** Human-readable message */
  message: string;
}

export interface JobRestoreRequest {
  /** restore jobs includes grabbed to run process (maybe run twice or more) */
  includeGrabbed?: boolean | undefined;
  limit?: number | undefined;
}

function createBaseCreateJobResponse(): CreateJobResponse {
  return { id: undefined, result: undefined };
}

export const CreateJobResponse: MessageFns<CreateJobResponse> = {
  encode(message: CreateJobResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.id !== undefined) {
      JobId.encode(message.id, writer.uint32(10).fork()).join();
    }
    if (message.result !== undefined) {
      JobResult.encode(message.result, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateJobResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateJobResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.id = JobId.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.result = JobResult.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  create(base?: DeepPartial<CreateJobResponse>): CreateJobResponse {
    return CreateJobResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CreateJobResponse>): CreateJobResponse {
    const message = createBaseCreateJobResponse();
    message.id = (object.id !== undefined && object.id !== null) ? JobId.fromPartial(object.id) : undefined;
    message.result = (object.result !== undefined && object.result !== null)
      ? JobResult.fromPartial(object.result)
      : undefined;
    return message;
  },
};

function createBaseOptionalJobResponse(): OptionalJobResponse {
  return { data: undefined };
}

export const OptionalJobResponse: MessageFns<OptionalJobResponse> = {
  encode(message: OptionalJobResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.data !== undefined) {
      Job.encode(message.data, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): OptionalJobResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseOptionalJobResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.data = Job.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  create(base?: DeepPartial<OptionalJobResponse>): OptionalJobResponse {
    return OptionalJobResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<OptionalJobResponse>): OptionalJobResponse {
    const message = createBaseOptionalJobResponse();
    message.data = (object.data !== undefined && object.data !== null) ? Job.fromPartial(object.data) : undefined;
    return message;
  },
};

function createBaseJobRequest(): JobRequest {
  return {
    workerId: undefined,
    workerName: undefined,
    args: new Uint8Array(0),
    uniqKey: undefined,
    runAfterTime: undefined,
    priority: undefined,
    timeout: undefined,
    using: undefined,
  };
}

export const JobRequest: MessageFns<JobRequest> = {
  encode(message: JobRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.workerId !== undefined) {
      WorkerId.encode(message.workerId, writer.uint32(10).fork()).join();
    }
    if (message.workerName !== undefined) {
      writer.uint32(18).string(message.workerName);
    }
    if (message.args.length !== 0) {
      writer.uint32(26).bytes(message.args);
    }
    if (message.uniqKey !== undefined) {
      writer.uint32(34).string(message.uniqKey);
    }
    if (message.runAfterTime !== undefined) {
      writer.uint32(40).int64(message.runAfterTime);
    }
    if (message.priority !== undefined) {
      writer.uint32(48).int32(message.priority);
    }
    if (message.timeout !== undefined) {
      writer.uint32(56).uint64(message.timeout);
    }
    if (message.using !== undefined) {
      writer.uint32(66).string(message.using);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): JobRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJobRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.workerId = WorkerId.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.workerName = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.args = reader.bytes();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.uniqKey = reader.string();
          continue;
        }
        case 5: {
          if (tag !== 40) {
            break;
          }

          message.runAfterTime = reader.int64().toString();
          continue;
        }
        case 6: {
          if (tag !== 48) {
            break;
          }

          message.priority = reader.int32() as any;
          continue;
        }
        case 7: {
          if (tag !== 56) {
            break;
          }

          message.timeout = reader.uint64().toString();
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          message.using = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  create(base?: DeepPartial<JobRequest>): JobRequest {
    return JobRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<JobRequest>): JobRequest {
    const message = createBaseJobRequest();
    message.workerId = (object.workerId !== undefined && object.workerId !== null)
      ? WorkerId.fromPartial(object.workerId)
      : undefined;
    message.workerName = object.workerName ?? undefined;
    message.args = object.args ?? new Uint8Array(0);
    message.uniqKey = object.uniqKey ?? undefined;
    message.runAfterTime = object.runAfterTime ?? undefined;
    message.priority = object.priority ?? undefined;
    message.timeout = object.timeout ?? undefined;
    message.using = object.using ?? undefined;
    return message;
  },
};

function createBaseFindQueueListRequest(): FindQueueListRequest {
  return { limit: undefined, channel: undefined };
}

export const FindQueueListRequest: MessageFns<FindQueueListRequest> = {
  encode(message: FindQueueListRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.limit !== undefined) {
      writer.uint32(8).int32(message.limit);
    }
    if (message.channel !== undefined) {
      writer.uint32(18).string(message.channel);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): FindQueueListRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFindQueueListRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.limit = reader.int32();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.channel = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  create(base?: DeepPartial<FindQueueListRequest>): FindQueueListRequest {
    return FindQueueListRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<FindQueueListRequest>): FindQueueListRequest {
    const message = createBaseFindQueueListRequest();
    message.limit = object.limit ?? undefined;
    message.channel = object.channel ?? undefined;
    return message;
  },
};

function createBaseFindListWithProcessingStatusRequest(): FindListWithProcessingStatusRequest {
  return { status: 0, limit: undefined };
}

export const FindListWithProcessingStatusRequest: MessageFns<FindListWithProcessingStatusRequest> = {
  encode(message: FindListWithProcessingStatusRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.status !== 0) {
      writer.uint32(8).int32(message.status);
    }
    if (message.limit !== undefined) {
      writer.uint32(16).int32(message.limit);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): FindListWithProcessingStatusRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFindListWithProcessingStatusRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.status = reader.int32() as any;
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.limit = reader.int32();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  create(base?: DeepPartial<FindListWithProcessingStatusRequest>): FindListWithProcessingStatusRequest {
    return FindListWithProcessingStatusRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<FindListWithProcessingStatusRequest>): FindListWithProcessingStatusRequest {
    const message = createBaseFindListWithProcessingStatusRequest();
    message.status = object.status ?? 0;
    message.limit = object.limit ?? undefined;
    return message;
  },
};

function createBaseJobAndStatus(): JobAndStatus {
  return { job: undefined, status: undefined };
}

export const JobAndStatus: MessageFns<JobAndStatus> = {
  encode(message: JobAndStatus, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.job !== undefined) {
      Job.encode(message.job, writer.uint32(10).fork()).join();
    }
    if (message.status !== undefined) {
      writer.uint32(16).int32(message.status);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): JobAndStatus {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJobAndStatus();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.job = Job.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.status = reader.int32() as any;
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  create(base?: DeepPartial<JobAndStatus>): JobAndStatus {
    return JobAndStatus.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<JobAndStatus>): JobAndStatus {
    const message = createBaseJobAndStatus();
    message.job = (object.job !== undefined && object.job !== null) ? Job.fromPartial(object.job) : undefined;
    message.status = object.status ?? undefined;
    return message;
  },
};

function createBaseJobProcessingStatusResponse(): JobProcessingStatusResponse {
  return { id: undefined, status: 0 };
}

export const JobProcessingStatusResponse: MessageFns<JobProcessingStatusResponse> = {
  encode(message: JobProcessingStatusResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.id !== undefined) {
      JobId.encode(message.id, writer.uint32(10).fork()).join();
    }
    if (message.status !== 0) {
      writer.uint32(16).int32(message.status);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): JobProcessingStatusResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJobProcessingStatusResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.id = JobId.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.status = reader.int32() as any;
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  create(base?: DeepPartial<JobProcessingStatusResponse>): JobProcessingStatusResponse {
    return JobProcessingStatusResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<JobProcessingStatusResponse>): JobProcessingStatusResponse {
    const message = createBaseJobProcessingStatusResponse();
    message.id = (object.id !== undefined && object.id !== null) ? JobId.fromPartial(object.id) : undefined;
    message.status = object.status ?? 0;
    return message;
  },
};

function createBaseOptionalJobProcessingStatusResponse(): OptionalJobProcessingStatusResponse {
  return { status: undefined };
}

export const OptionalJobProcessingStatusResponse: MessageFns<OptionalJobProcessingStatusResponse> = {
  encode(message: OptionalJobProcessingStatusResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.status !== undefined) {
      writer.uint32(8).int32(message.status);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): OptionalJobProcessingStatusResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseOptionalJobProcessingStatusResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.status = reader.int32() as any;
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  create(base?: DeepPartial<OptionalJobProcessingStatusResponse>): OptionalJobProcessingStatusResponse {
    return OptionalJobProcessingStatusResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<OptionalJobProcessingStatusResponse>): OptionalJobProcessingStatusResponse {
    const message = createBaseOptionalJobProcessingStatusResponse();
    message.status = object.status ?? undefined;
    return message;
  },
};

function createBaseFindJobProcessingStatusRequest(): FindJobProcessingStatusRequest {
  return {
    status: undefined,
    workerId: undefined,
    channel: undefined,
    minElapsedTimeMs: undefined,
    limit: undefined,
    offset: undefined,
    descending: undefined,
  };
}

export const FindJobProcessingStatusRequest: MessageFns<FindJobProcessingStatusRequest> = {
  encode(message: FindJobProcessingStatusRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.status !== undefined) {
      writer.uint32(8).int32(message.status);
    }
    if (message.workerId !== undefined) {
      writer.uint32(16).int64(message.workerId);
    }
    if (message.channel !== undefined) {
      writer.uint32(26).string(message.channel);
    }
    if (message.minElapsedTimeMs !== undefined) {
      writer.uint32(32).int64(message.minElapsedTimeMs);
    }
    if (message.limit !== undefined) {
      writer.uint32(40).int32(message.limit);
    }
    if (message.offset !== undefined) {
      writer.uint32(48).int32(message.offset);
    }
    if (message.descending !== undefined) {
      writer.uint32(56).bool(message.descending);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): FindJobProcessingStatusRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFindJobProcessingStatusRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.status = reader.int32() as any;
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.workerId = reader.int64().toString();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.channel = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 32) {
            break;
          }

          message.minElapsedTimeMs = reader.int64().toString();
          continue;
        }
        case 5: {
          if (tag !== 40) {
            break;
          }

          message.limit = reader.int32();
          continue;
        }
        case 6: {
          if (tag !== 48) {
            break;
          }

          message.offset = reader.int32();
          continue;
        }
        case 7: {
          if (tag !== 56) {
            break;
          }

          message.descending = reader.bool();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  create(base?: DeepPartial<FindJobProcessingStatusRequest>): FindJobProcessingStatusRequest {
    return FindJobProcessingStatusRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<FindJobProcessingStatusRequest>): FindJobProcessingStatusRequest {
    const message = createBaseFindJobProcessingStatusRequest();
    message.status = object.status ?? undefined;
    message.workerId = object.workerId ?? undefined;
    message.channel = object.channel ?? undefined;
    message.minElapsedTimeMs = object.minElapsedTimeMs ?? undefined;
    message.limit = object.limit ?? undefined;
    message.offset = object.offset ?? undefined;
    message.descending = object.descending ?? undefined;
    return message;
  },
};

function createBaseJobProcessingStatusDetailResponse(): JobProcessingStatusDetailResponse {
  return {
    id: undefined,
    status: 0,
    workerId: "0",
    channel: "",
    priority: 0,
    enqueueTime: "0",
    startTime: undefined,
    pendingTime: undefined,
    isStreamable: undefined,
    broadcastResults: undefined,
    updatedAt: "0",
  };
}

export const JobProcessingStatusDetailResponse: MessageFns<JobProcessingStatusDetailResponse> = {
  encode(message: JobProcessingStatusDetailResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.id !== undefined) {
      JobId.encode(message.id, writer.uint32(10).fork()).join();
    }
    if (message.status !== 0) {
      writer.uint32(16).int32(message.status);
    }
    if (message.workerId !== "0") {
      writer.uint32(24).int64(message.workerId);
    }
    if (message.channel !== "") {
      writer.uint32(34).string(message.channel);
    }
    if (message.priority !== 0) {
      writer.uint32(40).int32(message.priority);
    }
    if (message.enqueueTime !== "0") {
      writer.uint32(48).int64(message.enqueueTime);
    }
    if (message.startTime !== undefined) {
      writer.uint32(56).int64(message.startTime);
    }
    if (message.pendingTime !== undefined) {
      writer.uint32(64).int64(message.pendingTime);
    }
    if (message.isStreamable !== undefined) {
      writer.uint32(72).bool(message.isStreamable);
    }
    if (message.broadcastResults !== undefined) {
      writer.uint32(80).bool(message.broadcastResults);
    }
    if (message.updatedAt !== "0") {
      writer.uint32(88).int64(message.updatedAt);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): JobProcessingStatusDetailResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJobProcessingStatusDetailResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.id = JobId.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.status = reader.int32() as any;
          continue;
        }
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.workerId = reader.int64().toString();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.channel = reader.string();
          continue;
        }
        case 5: {
          if (tag !== 40) {
            break;
          }

          message.priority = reader.int32();
          continue;
        }
        case 6: {
          if (tag !== 48) {
            break;
          }

          message.enqueueTime = reader.int64().toString();
          continue;
        }
        case 7: {
          if (tag !== 56) {
            break;
          }

          message.startTime = reader.int64().toString();
          continue;
        }
        case 8: {
          if (tag !== 64) {
            break;
          }

          message.pendingTime = reader.int64().toString();
          continue;
        }
        case 9: {
          if (tag !== 72) {
            break;
          }

          message.isStreamable = reader.bool();
          continue;
        }
        case 10: {
          if (tag !== 80) {
            break;
          }

          message.broadcastResults = reader.bool();
          continue;
        }
        case 11: {
          if (tag !== 88) {
            break;
          }

          message.updatedAt = reader.int64().toString();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  create(base?: DeepPartial<JobProcessingStatusDetailResponse>): JobProcessingStatusDetailResponse {
    return JobProcessingStatusDetailResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<JobProcessingStatusDetailResponse>): JobProcessingStatusDetailResponse {
    const message = createBaseJobProcessingStatusDetailResponse();
    message.id = (object.id !== undefined && object.id !== null) ? JobId.fromPartial(object.id) : undefined;
    message.status = object.status ?? 0;
    message.workerId = object.workerId ?? "0";
    message.channel = object.channel ?? "";
    message.priority = object.priority ?? 0;
    message.enqueueTime = object.enqueueTime ?? "0";
    message.startTime = object.startTime ?? undefined;
    message.pendingTime = object.pendingTime ?? undefined;
    message.isStreamable = object.isStreamable ?? undefined;
    message.broadcastResults = object.broadcastResults ?? undefined;
    message.updatedAt = object.updatedAt ?? "0";
    return message;
  },
};

function createBaseCleanupRequest(): CleanupRequest {
  return { retentionHoursOverride: undefined };
}

export const CleanupRequest: MessageFns<CleanupRequest> = {
  encode(message: CleanupRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.retentionHoursOverride !== undefined) {
      writer.uint32(8).uint64(message.retentionHoursOverride);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CleanupRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCleanupRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.retentionHoursOverride = reader.uint64().toString();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  create(base?: DeepPartial<CleanupRequest>): CleanupRequest {
    return CleanupRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CleanupRequest>): CleanupRequest {
    const message = createBaseCleanupRequest();
    message.retentionHoursOverride = object.retentionHoursOverride ?? undefined;
    return message;
  },
};

function createBaseCleanupResponse(): CleanupResponse {
  return { deletedCount: "0", cutoffTime: "0", message: "" };
}

export const CleanupResponse: MessageFns<CleanupResponse> = {
  encode(message: CleanupResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.deletedCount !== "0") {
      writer.uint32(8).uint64(message.deletedCount);
    }
    if (message.cutoffTime !== "0") {
      writer.uint32(16).int64(message.cutoffTime);
    }
    if (message.message !== "") {
      writer.uint32(26).string(message.message);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CleanupResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCleanupResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.deletedCount = reader.uint64().toString();
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.cutoffTime = reader.int64().toString();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.message = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  create(base?: DeepPartial<CleanupResponse>): CleanupResponse {
    return CleanupResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CleanupResponse>): CleanupResponse {
    const message = createBaseCleanupResponse();
    message.deletedCount = object.deletedCount ?? "0";
    message.cutoffTime = object.cutoffTime ?? "0";
    message.message = object.message ?? "";
    return message;
  },
};

function createBaseJobRestoreRequest(): JobRestoreRequest {
  return { includeGrabbed: undefined, limit: undefined };
}

export const JobRestoreRequest: MessageFns<JobRestoreRequest> = {
  encode(message: JobRestoreRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.includeGrabbed !== undefined) {
      writer.uint32(8).bool(message.includeGrabbed);
    }
    if (message.limit !== undefined) {
      writer.uint32(16).int32(message.limit);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): JobRestoreRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJobRestoreRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.includeGrabbed = reader.bool();
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.limit = reader.int32();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  create(base?: DeepPartial<JobRestoreRequest>): JobRestoreRequest {
    return JobRestoreRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<JobRestoreRequest>): JobRestoreRequest {
    const message = createBaseJobRestoreRequest();
    message.includeGrabbed = object.includeGrabbed ?? undefined;
    message.limit = object.limit ?? undefined;
    return message;
  },
};

export type JobServiceDefinition = typeof JobServiceDefinition;
export const JobServiceDefinition = {
  name: "JobService",
  fullName: "jobworkerp.service.JobService",
  methods: {
    enqueue: {
      name: "Enqueue",
      requestType: JobRequest,
      requestStream: false,
      responseType: CreateJobResponse,
      responseStream: false,
      options: {},
    },
    /**
     * Direct response only, JobResult on metadata header of grpc response
     * TODO Now support only for worker with storage_type: Scalable
     */
    enqueueForStream: {
      name: "EnqueueForStream",
      requestType: JobRequest,
      requestStream: false,
      responseType: ResultOutputItem,
      responseStream: true,
      options: {},
    },
    /**
     * Delete/Cancel job
     *
     * - Before execution (PENDING): Deletes the job from queue (no JobResult created)
     * - During/After execution (RUNNING, WAIT_RESULT): Cancels the job and generates JobResult with CANCELLED status
     *
     * Note: Job records are always deleted after execution. JobResult records remain for audit purposes.
     */
    delete: {
      name: "Delete",
      requestType: JobId,
      requestStream: false,
      responseType: SuccessResponse,
      responseStream: false,
      options: {},
    },
    /** only use db or redis+db queue type, run after or periodic worker jobs */
    find: {
      name: "Find",
      requestType: JobId,
      requestStream: false,
      responseType: OptionalJobResponse,
      responseStream: false,
      options: {},
    },
    /** only use db or redis+db queue type, run after or periodic worker jobs */
    findList: {
      name: "FindList",
      requestType: FindListRequest,
      requestStream: false,
      responseType: Job,
      responseStream: true,
      options: {},
    },
    findQueueList: {
      name: "FindQueueList",
      requestType: FindQueueListRequest,
      requestStream: false,
      responseType: JobAndStatus,
      responseStream: true,
      options: {},
    },
    /** find jobs by processing status (Pending, Running, WaitResult, Cancelling) */
    findListWithProcessingStatus: {
      name: "FindListWithProcessingStatus",
      requestType: FindListWithProcessingStatusRequest,
      requestStream: false,
      responseType: JobAndStatus,
      responseStream: true,
      options: {},
    },
    count: {
      name: "Count",
      requestType: CountCondition,
      requestStream: false,
      responseType: CountResponse,
      responseStream: false,
      options: {},
    },
  },
} as const;

export type JobProcessingStatusServiceDefinition = typeof JobProcessingStatusServiceDefinition;
export const JobProcessingStatusServiceDefinition = {
  name: "JobProcessingStatusService",
  fullName: "jobworkerp.service.JobProcessingStatusService",
  methods: {
    find: {
      name: "Find",
      requestType: JobId,
      requestStream: false,
      responseType: OptionalJobProcessingStatusResponse,
      responseStream: false,
      options: {},
    },
    findAll: {
      name: "FindAll",
      requestType: Empty,
      requestStream: false,
      responseType: JobProcessingStatusResponse,
      responseStream: true,
      options: {},
    },
    /**
     * Advanced search using RDB index
     * Returns UNIMPLEMENTED error if JOB_STATUS_RDB_INDEXING=false
     */
    findByCondition: {
      name: "FindByCondition",
      requestType: FindJobProcessingStatusRequest,
      requestStream: false,
      responseType: JobProcessingStatusDetailResponse,
      responseStream: true,
      options: {},
    },
    /**
     * Cleanup logically deleted records from job_processing_status table
     *
     * This operation physically deletes records marked as deleted (deleted_at IS NOT NULL)
     * that are older than JOB_STATUS_RETENTION_HOURS (default: 24 hours).
     *
     * Requirements:
     * - JOB_STATUS_RDB_INDEXING=true (returns FAILED_PRECONDITION if disabled)
     * - AUTH_TOKEN environment variable must match jobworkerp-auth header (if set)
     *
     * Returns:
     * - deleted_count: Number of deleted records
     * - cutoff_time: Timestamp used for deletion cutoff (milliseconds since epoch)
     *
     * Errors:
     * - UNAUTHENTICATED: Missing or invalid AUTH_TOKEN (if AUTH_TOKEN env is set)
     * - FAILED_PRECONDITION: JOB_STATUS_RDB_INDEXING is disabled
     * - INTERNAL: Database error during cleanup
     */
    cleanup: {
      name: "Cleanup",
      requestType: CleanupRequest,
      requestStream: false,
      responseType: CleanupResponse,
      responseStream: false,
      options: {},
    },
  },
} as const;

/**
 * [for Scalable storage only] restore jobs from rdb to redis
 * (for lost job insident in redis)
 * (except for periodic jobs and jobs with run_after_time)
 */
export type JobRestoreServiceDefinition = typeof JobRestoreServiceDefinition;
export const JobRestoreServiceDefinition = {
  name: "JobRestoreService",
  fullName: "jobworkerp.service.JobRestoreService",
  methods: {
    restore: {
      name: "Restore",
      requestType: JobRestoreRequest,
      requestStream: false,
      responseType: SuccessResponse,
      responseStream: false,
      options: {},
    },
    /** find all jobs to restore */
    findAll: {
      name: "FindAll",
      requestType: JobRestoreRequest,
      requestStream: false,
      responseType: Job,
      responseStream: true,
      options: {},
    },
  },
} as const;

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
