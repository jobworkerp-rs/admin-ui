// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.8.3
//   protoc               v6.33.1
// source: jobworkerp/data/job_result.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import { Priority, ResponseType, ResultOutput, ResultStatus, StreamingType } from "./common";
import { JobId } from "./job";
import { WorkerId } from "./worker";

export const protobufPackage = "jobworkerp.data";

/**
 * # Job Result Sort Field
 * Defines the fields available for sorting job results in queries
 */
export enum JobResultSortField {
  JOB_RESULT_SORT_FIELD_UNSPECIFIED = 0,
  JOB_RESULT_SORT_FIELD_ID = 1,
  JOB_RESULT_SORT_FIELD_START_TIME = 2,
  JOB_RESULT_SORT_FIELD_END_TIME = 3,
  JOB_RESULT_SORT_FIELD_STATUS = 4,
  UNRECOGNIZED = -1,
}

/**
 * # Job Result Data
 * Contains the execution result and metadata of a job
 * Note: JobResult does not have its own ID in the system
 */
export interface JobResultData {
  /**
   * # Job ID
   * Reference to the job that was executed
   */
  jobId:
    | JobId
    | undefined;
  /**
   * # Worker ID
   * Reference to the worker that executed the job
   */
  workerId:
    | WorkerId
    | undefined;
  /**
   * # Worker Name
   * Name of the worker that executed the job
   */
  workerName: string;
  /**
   * # Arguments
   * Serialized arguments that were passed to the job
   */
  args: Uint8Array;
  /**
   * # Unique Key
   * Optional unique identifier that was used for job deduplication
   */
  uniqKey?:
    | string
    | undefined;
  /**
   * # Result Status
   * Execution status of the job (success, failure, etc.)
   */
  status: ResultStatus;
  /**
   * # Result Output
   * Job execution output data (non-streaming)
   */
  output:
    | ResultOutput
    | undefined;
  /**
   * # Retry Count
   * Number of times this job was retried after failure
   */
  retried: number;
  /**
   * # Maximum Retry Count
   * Maximum number of retry attempts allowed for this job
   */
  maxRetry: number;
  /**
   * # Priority
   * Execution priority level of the job
   */
  priority: Priority;
  /**
   * # Timeout
   * from enqueue arguments
   */
  timeout: string;
  /**
   * # Streaming Type
   * Defines how streaming is handled for this job result
   * Values: 0=None, 1=Response (client streaming), 2=Internal (worker-side collection)
   */
  streamingType: StreamingType;
  /**
   * # Enqueue Time
   * Timestamp when the job was registered in the queue (Unix time in milliseconds)
   */
  enqueueTime: string;
  /**
   * # Run After Time
   * Timestamp when the job was scheduled to execute (specified by client)
   */
  runAfterTime: string;
  /**
   * # Start Time
   * Timestamp when the job execution started (Unix time in milliseconds)
   */
  startTime: string;
  /**
   * # End Time
   * Timestamp when the job execution completed (Unix time in milliseconds)
   */
  endTime: string;
  /**
   * # Response Type
   * How the result should be handled (none, direct, listen after)
   */
  responseType: ResponseType;
  /**
   * # Store Success Flag
   * from worker.data.store_success
   */
  storeSuccess: boolean;
  /**
   * # Store Failure Flag
   * from worker.data.store_failure
   */
  storeFailure: boolean;
  /**
   * # Using
   * Runner implementation used for MCP/Plugin runners
   * Preserved for retry and periodic job re-execution
   */
  using?: string | undefined;
}

/**
 * # Job Result ID
 * Unique identifier for a job result record
 */
export interface JobResultId {
  value: string;
}

/**
 * # Job Result
 * Complete record of a job execution result with metadata
 * worker.data.store_success and worker.data.store_failure flags determine if
 * the result is stored in the database
 */
export interface JobResult {
  id: JobResultId | undefined;
  data: JobResultData | undefined;
  metadata: { [key: string]: string };
}

export interface JobResult_MetadataEntry {
  key: string;
  value: string;
}

function createBaseJobResultData(): JobResultData {
  return {
    jobId: undefined,
    workerId: undefined,
    workerName: "",
    args: new Uint8Array(0),
    uniqKey: undefined,
    status: 0,
    output: undefined,
    retried: 0,
    maxRetry: 0,
    priority: 0,
    timeout: "0",
    streamingType: 0,
    enqueueTime: "0",
    runAfterTime: "0",
    startTime: "0",
    endTime: "0",
    responseType: 0,
    storeSuccess: false,
    storeFailure: false,
    using: undefined,
  };
}

export const JobResultData: MessageFns<JobResultData> = {
  encode(message: JobResultData, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.jobId !== undefined) {
      JobId.encode(message.jobId, writer.uint32(10).fork()).join();
    }
    if (message.workerId !== undefined) {
      WorkerId.encode(message.workerId, writer.uint32(18).fork()).join();
    }
    if (message.workerName !== "") {
      writer.uint32(26).string(message.workerName);
    }
    if (message.args.length !== 0) {
      writer.uint32(34).bytes(message.args);
    }
    if (message.uniqKey !== undefined) {
      writer.uint32(42).string(message.uniqKey);
    }
    if (message.status !== 0) {
      writer.uint32(48).int32(message.status);
    }
    if (message.output !== undefined) {
      ResultOutput.encode(message.output, writer.uint32(58).fork()).join();
    }
    if (message.retried !== 0) {
      writer.uint32(64).uint32(message.retried);
    }
    if (message.maxRetry !== 0) {
      writer.uint32(72).uint32(message.maxRetry);
    }
    if (message.priority !== 0) {
      writer.uint32(80).int32(message.priority);
    }
    if (message.timeout !== "0") {
      writer.uint32(88).uint64(message.timeout);
    }
    if (message.streamingType !== 0) {
      writer.uint32(168).int32(message.streamingType);
    }
    if (message.enqueueTime !== "0") {
      writer.uint32(104).int64(message.enqueueTime);
    }
    if (message.runAfterTime !== "0") {
      writer.uint32(112).int64(message.runAfterTime);
    }
    if (message.startTime !== "0") {
      writer.uint32(120).int64(message.startTime);
    }
    if (message.endTime !== "0") {
      writer.uint32(128).int64(message.endTime);
    }
    if (message.responseType !== 0) {
      writer.uint32(136).int32(message.responseType);
    }
    if (message.storeSuccess !== false) {
      writer.uint32(144).bool(message.storeSuccess);
    }
    if (message.storeFailure !== false) {
      writer.uint32(152).bool(message.storeFailure);
    }
    if (message.using !== undefined) {
      writer.uint32(162).string(message.using);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): JobResultData {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJobResultData();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.jobId = JobId.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.workerId = WorkerId.decode(reader, reader.uint32());
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.workerName = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.args = reader.bytes();
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.uniqKey = reader.string();
          continue;
        }
        case 6: {
          if (tag !== 48) {
            break;
          }

          message.status = reader.int32() as any;
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.output = ResultOutput.decode(reader, reader.uint32());
          continue;
        }
        case 8: {
          if (tag !== 64) {
            break;
          }

          message.retried = reader.uint32();
          continue;
        }
        case 9: {
          if (tag !== 72) {
            break;
          }

          message.maxRetry = reader.uint32();
          continue;
        }
        case 10: {
          if (tag !== 80) {
            break;
          }

          message.priority = reader.int32() as any;
          continue;
        }
        case 11: {
          if (tag !== 88) {
            break;
          }

          message.timeout = reader.uint64().toString();
          continue;
        }
        case 21: {
          if (tag !== 168) {
            break;
          }

          message.streamingType = reader.int32() as any;
          continue;
        }
        case 13: {
          if (tag !== 104) {
            break;
          }

          message.enqueueTime = reader.int64().toString();
          continue;
        }
        case 14: {
          if (tag !== 112) {
            break;
          }

          message.runAfterTime = reader.int64().toString();
          continue;
        }
        case 15: {
          if (tag !== 120) {
            break;
          }

          message.startTime = reader.int64().toString();
          continue;
        }
        case 16: {
          if (tag !== 128) {
            break;
          }

          message.endTime = reader.int64().toString();
          continue;
        }
        case 17: {
          if (tag !== 136) {
            break;
          }

          message.responseType = reader.int32() as any;
          continue;
        }
        case 18: {
          if (tag !== 144) {
            break;
          }

          message.storeSuccess = reader.bool();
          continue;
        }
        case 19: {
          if (tag !== 152) {
            break;
          }

          message.storeFailure = reader.bool();
          continue;
        }
        case 20: {
          if (tag !== 162) {
            break;
          }

          message.using = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  create(base?: DeepPartial<JobResultData>): JobResultData {
    return JobResultData.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<JobResultData>): JobResultData {
    const message = createBaseJobResultData();
    message.jobId = (object.jobId !== undefined && object.jobId !== null) ? JobId.fromPartial(object.jobId) : undefined;
    message.workerId = (object.workerId !== undefined && object.workerId !== null)
      ? WorkerId.fromPartial(object.workerId)
      : undefined;
    message.workerName = object.workerName ?? "";
    message.args = object.args ?? new Uint8Array(0);
    message.uniqKey = object.uniqKey ?? undefined;
    message.status = object.status ?? 0;
    message.output = (object.output !== undefined && object.output !== null)
      ? ResultOutput.fromPartial(object.output)
      : undefined;
    message.retried = object.retried ?? 0;
    message.maxRetry = object.maxRetry ?? 0;
    message.priority = object.priority ?? 0;
    message.timeout = object.timeout ?? "0";
    message.streamingType = object.streamingType ?? 0;
    message.enqueueTime = object.enqueueTime ?? "0";
    message.runAfterTime = object.runAfterTime ?? "0";
    message.startTime = object.startTime ?? "0";
    message.endTime = object.endTime ?? "0";
    message.responseType = object.responseType ?? 0;
    message.storeSuccess = object.storeSuccess ?? false;
    message.storeFailure = object.storeFailure ?? false;
    message.using = object.using ?? undefined;
    return message;
  },
};

function createBaseJobResultId(): JobResultId {
  return { value: "0" };
}

export const JobResultId: MessageFns<JobResultId> = {
  encode(message: JobResultId, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.value !== "0") {
      writer.uint32(8).int64(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): JobResultId {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJobResultId();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.value = reader.int64().toString();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  create(base?: DeepPartial<JobResultId>): JobResultId {
    return JobResultId.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<JobResultId>): JobResultId {
    const message = createBaseJobResultId();
    message.value = object.value ?? "0";
    return message;
  },
};

function createBaseJobResult(): JobResult {
  return { id: undefined, data: undefined, metadata: {} };
}

export const JobResult: MessageFns<JobResult> = {
  encode(message: JobResult, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.id !== undefined) {
      JobResultId.encode(message.id, writer.uint32(10).fork()).join();
    }
    if (message.data !== undefined) {
      JobResultData.encode(message.data, writer.uint32(18).fork()).join();
    }
    Object.entries(message.metadata).forEach(([key, value]) => {
      JobResult_MetadataEntry.encode({ key: key as any, value }, writer.uint32(26).fork()).join();
    });
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): JobResult {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJobResult();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.id = JobResultId.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.data = JobResultData.decode(reader, reader.uint32());
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          const entry3 = JobResult_MetadataEntry.decode(reader, reader.uint32());
          if (entry3.value !== undefined) {
            message.metadata[entry3.key] = entry3.value;
          }
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  create(base?: DeepPartial<JobResult>): JobResult {
    return JobResult.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<JobResult>): JobResult {
    const message = createBaseJobResult();
    message.id = (object.id !== undefined && object.id !== null) ? JobResultId.fromPartial(object.id) : undefined;
    message.data = (object.data !== undefined && object.data !== null)
      ? JobResultData.fromPartial(object.data)
      : undefined;
    message.metadata = Object.entries(object.metadata ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    return message;
  },
};

function createBaseJobResult_MetadataEntry(): JobResult_MetadataEntry {
  return { key: "", value: "" };
}

export const JobResult_MetadataEntry: MessageFns<JobResult_MetadataEntry> = {
  encode(message: JobResult_MetadataEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): JobResult_MetadataEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJobResult_MetadataEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  create(base?: DeepPartial<JobResult_MetadataEntry>): JobResult_MetadataEntry {
    return JobResult_MetadataEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<JobResult_MetadataEntry>): JobResult_MetadataEntry {
    const message = createBaseJobResult_MetadataEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
