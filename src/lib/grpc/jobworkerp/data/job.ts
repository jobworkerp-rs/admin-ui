// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.8.3
//   protoc               v6.33.1
// source: jobworkerp/data/job.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import { Priority, StreamingType } from "./common";
import { WorkerId } from "./worker";

export const protobufPackage = "jobworkerp.data";

/**
 * # Job Data
 * Configuration and state for a job that will be executed by a worker
 */
export interface JobData {
  /**
   * # Worker ID
   * Reference to the worker that will execute this job
   */
  workerId:
    | WorkerId
    | undefined;
  /**
   * # Job Arguments
   * Serialized arguments that will be passed to the runner
   */
  args: Uint8Array;
  /**
   * # Unique Key
   * Optional identifier to prevent duplicate job registration
   * Jobs with the same unique key cannot be registered simultaneously
   */
  uniqKey?:
    | string
    | undefined;
  /**
   * # Enqueue Time
   * Timestamp when the job was registered in the queue (Unix time in milliseconds)
   */
  enqueueTime: string;
  /**
   * # Grabbed Until Time
   * Timestamp until which the job is locked for processing (Unix time in
   * milliseconds) This should not be specified manually - it's set by the system
   */
  grabbedUntilTime?:
    | string
    | undefined;
  /**
   * # Run After Time
   * Timestamp when the job should be executed (Unix time in milliseconds)
   * Jobs will not be processed until this time is reached
   */
  runAfterTime: string;
  /**
   * # Retry Count
   * Number of times this job has been retried after failure
   */
  retried: number;
  /**
   * # Priority
   * Execution priority level: -1 (low), 0 (normal), 1 (high)
   * Note: Using enum directly in proto is not possible due to reference
   * limitations
   */
  priority: Priority;
  /**
   * # Timeout
   * Maximum execution time for the job in milliseconds
   * Job will be terminated if it exceeds this duration
   */
  timeout: string;
  /**
   * # Streaming Type
   * Defines how streaming is handled for this job execution.
   * - STREAMING_TYPE_NONE (default): Non-streaming execution using run()
   * - STREAMING_TYPE_INTERNAL: Uses run_stream() internally but collects
   *   result with collect_stream() and returns as single JobResult
   * - STREAMING_TYPE_RESPONSE: Full streaming, results streamed to client
   */
  streamingType: StreamingType;
  /**
   * # Using
   * Selects which method to use for multi-method runners
   * - Required: For multi-method runners
   * - Auto-selected: When omitted for single-method runners
   * - Ignored: For single-method runners
   */
  using?: string | undefined;
}

/**
 * # Job ID
 * Unique identifier for a job
 */
export interface JobId {
  value: string;
}

/**
 * # Job
 * A job that is executed by a worker
 */
export interface Job {
  id: JobId | undefined;
  data: JobData | undefined;
  metadata: { [key: string]: string };
}

export interface Job_MetadataEntry {
  key: string;
  value: string;
}

function createBaseJobData(): JobData {
  return {
    workerId: undefined,
    args: new Uint8Array(0),
    uniqKey: undefined,
    enqueueTime: "0",
    grabbedUntilTime: undefined,
    runAfterTime: "0",
    retried: 0,
    priority: 0,
    timeout: "0",
    streamingType: 0,
    using: undefined,
  };
}

export const JobData: MessageFns<JobData> = {
  encode(message: JobData, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.workerId !== undefined) {
      WorkerId.encode(message.workerId, writer.uint32(10).fork()).join();
    }
    if (message.args.length !== 0) {
      writer.uint32(18).bytes(message.args);
    }
    if (message.uniqKey !== undefined) {
      writer.uint32(26).string(message.uniqKey);
    }
    if (message.enqueueTime !== "0") {
      writer.uint32(32).int64(message.enqueueTime);
    }
    if (message.grabbedUntilTime !== undefined) {
      writer.uint32(40).int64(message.grabbedUntilTime);
    }
    if (message.runAfterTime !== "0") {
      writer.uint32(48).int64(message.runAfterTime);
    }
    if (message.retried !== 0) {
      writer.uint32(56).uint32(message.retried);
    }
    if (message.priority !== 0) {
      writer.uint32(64).int32(message.priority);
    }
    if (message.timeout !== "0") {
      writer.uint32(72).uint64(message.timeout);
    }
    if (message.streamingType !== 0) {
      writer.uint32(96).int32(message.streamingType);
    }
    if (message.using !== undefined) {
      writer.uint32(90).string(message.using);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): JobData {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJobData();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.workerId = WorkerId.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.args = reader.bytes();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.uniqKey = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 32) {
            break;
          }

          message.enqueueTime = reader.int64().toString();
          continue;
        }
        case 5: {
          if (tag !== 40) {
            break;
          }

          message.grabbedUntilTime = reader.int64().toString();
          continue;
        }
        case 6: {
          if (tag !== 48) {
            break;
          }

          message.runAfterTime = reader.int64().toString();
          continue;
        }
        case 7: {
          if (tag !== 56) {
            break;
          }

          message.retried = reader.uint32();
          continue;
        }
        case 8: {
          if (tag !== 64) {
            break;
          }

          message.priority = reader.int32() as any;
          continue;
        }
        case 9: {
          if (tag !== 72) {
            break;
          }

          message.timeout = reader.uint64().toString();
          continue;
        }
        case 12: {
          if (tag !== 96) {
            break;
          }

          message.streamingType = reader.int32() as any;
          continue;
        }
        case 11: {
          if (tag !== 90) {
            break;
          }

          message.using = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  create(base?: DeepPartial<JobData>): JobData {
    return JobData.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<JobData>): JobData {
    const message = createBaseJobData();
    message.workerId = (object.workerId !== undefined && object.workerId !== null)
      ? WorkerId.fromPartial(object.workerId)
      : undefined;
    message.args = object.args ?? new Uint8Array(0);
    message.uniqKey = object.uniqKey ?? undefined;
    message.enqueueTime = object.enqueueTime ?? "0";
    message.grabbedUntilTime = object.grabbedUntilTime ?? undefined;
    message.runAfterTime = object.runAfterTime ?? "0";
    message.retried = object.retried ?? 0;
    message.priority = object.priority ?? 0;
    message.timeout = object.timeout ?? "0";
    message.streamingType = object.streamingType ?? 0;
    message.using = object.using ?? undefined;
    return message;
  },
};

function createBaseJobId(): JobId {
  return { value: "0" };
}

export const JobId: MessageFns<JobId> = {
  encode(message: JobId, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.value !== "0") {
      writer.uint32(8).int64(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): JobId {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJobId();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.value = reader.int64().toString();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  create(base?: DeepPartial<JobId>): JobId {
    return JobId.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<JobId>): JobId {
    const message = createBaseJobId();
    message.value = object.value ?? "0";
    return message;
  },
};

function createBaseJob(): Job {
  return { id: undefined, data: undefined, metadata: {} };
}

export const Job: MessageFns<Job> = {
  encode(message: Job, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.id !== undefined) {
      JobId.encode(message.id, writer.uint32(10).fork()).join();
    }
    if (message.data !== undefined) {
      JobData.encode(message.data, writer.uint32(18).fork()).join();
    }
    Object.entries(message.metadata).forEach(([key, value]) => {
      Job_MetadataEntry.encode({ key: key as any, value }, writer.uint32(26).fork()).join();
    });
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Job {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJob();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.id = JobId.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.data = JobData.decode(reader, reader.uint32());
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          const entry3 = Job_MetadataEntry.decode(reader, reader.uint32());
          if (entry3.value !== undefined) {
            message.metadata[entry3.key] = entry3.value;
          }
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  create(base?: DeepPartial<Job>): Job {
    return Job.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Job>): Job {
    const message = createBaseJob();
    message.id = (object.id !== undefined && object.id !== null) ? JobId.fromPartial(object.id) : undefined;
    message.data = (object.data !== undefined && object.data !== null) ? JobData.fromPartial(object.data) : undefined;
    message.metadata = Object.entries(object.metadata ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    return message;
  },
};

function createBaseJob_MetadataEntry(): Job_MetadataEntry {
  return { key: "", value: "" };
}

export const Job_MetadataEntry: MessageFns<Job_MetadataEntry> = {
  encode(message: Job_MetadataEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Job_MetadataEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJob_MetadataEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  create(base?: DeepPartial<Job_MetadataEntry>): Job_MetadataEntry {
    return Job_MetadataEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Job_MetadataEntry>): Job_MetadataEntry {
    const message = createBaseJob_MetadataEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
